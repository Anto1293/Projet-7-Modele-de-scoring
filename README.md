# ğŸ“Š Projet 7 - ModÃ¨le de Scoring CrÃ©dit

Ce projet a pour objectif de construire un modÃ¨le de scoring permettant de prÃ©dire la probabilitÃ© de dÃ©faut de paiement dâ€™un client, et de dÃ©terminer si son crÃ©dit doit Ãªtre accordÃ© ou refusÃ©.

## ğŸ¯ Objectifs
- Construire un modÃ¨le de prÃ©diction robuste
- Expliquer les prÃ©dictions (feature importance globale et locale)
- Mettre en production une API
- Suivre les performances du modÃ¨le avec MLflow et Evidently
- DÃ©ployer automatiquement l'API avec GitHub Actions

## ğŸ§° Outils utilisÃ©s
- Python, Jupyter Notebook
- Scikit-learn, LightGBM, SHAP, imbalanced-learn
- MLflow
- FastAPI pour lâ€™API
- Streamlit pour lâ€™interface utilisateur
- Evidently pour la dÃ©tection de data drift
- Git, GitHub, GitHub Actions pour le CI/CD

## ğŸ“¥ DonnÃ©es utilisÃ©es
Les fichiers de donnÃ©es proviennent du dataset Home Credit Default Risk :  
[https://www.kaggle.com/competitions/home-credit-default-risk/data]
Pour lancer le code, placez les fichiers `.csv` dans le dossier `data/`.
Le chargement se fait automatiquement via la fonction `load_all_data(data_dir)`.

## ğŸ—‚ï¸ Structure du projet

Projet 7 ModÃ¨le de scoring/
â”œâ”€â”€ api/ # Code de l'API FastAPI
â”œâ”€â”€ streamlit/ # Interface utilisateur Streamlit
â”œâ”€â”€ src/ # Fonctions Python gÃ©nÃ©riques
â”œâ”€â”€ data/ # DonnÃ©es et objets enregistrÃ©s (y_val, seuils, etc.)
â”œâ”€â”€ bdd/ # DonnÃ©es brutes externes
â”œâ”€â”€ mlartifacts/ # Artifacts produits par MLflow
â”œâ”€â”€ mlruns/ # Dossiers MLflow
â”œâ”€â”€ models/ # ModÃ¨les entraÃ®nÃ©s et enregistrÃ©s
â”œâ”€â”€ notebooks/ # Notebooks dâ€™analyse, modÃ©lisation et suivi
â”œâ”€â”€ tests/ # Tests unitaires Pytest
â”œâ”€â”€ evidently_report.html # Rapport HTML de data drift
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ environment.yml
â””â”€â”€ README.md

## ğŸ› ï¸ Installation rapide
bash
# Cloner le repo
git clone [https://github.com/ton-utilisateur/ton-repo.git]
cd ton-repo

# Installer les dÃ©pendances
pip install -r requirements.txt

## âš™ï¸ Lancer l'API localement
cd api
uvicorn app:app --reload

## ğŸ“² Tester avec Streamlit
cd streamlit
streamlit run streamlit_app.py
Network URL: [http://192.168.1.11:8501]

## ğŸ§ª Lancer les tests
pytest -s tests/

## ğŸ“¦ DÃ©pendances
Voir requirements.txt ou environment.yml

## â˜ï¸ DÃ©ploiement cloud
Lâ€™API est dÃ©ployÃ©e sur [Lien API ici]

## ğŸ“Š Suivi MLflow
Interface de tracking disponible en local sur :[http://localhost:5000]